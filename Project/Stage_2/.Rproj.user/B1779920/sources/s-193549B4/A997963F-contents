---
title: "Project Stage 2"
author: "Guillermo"
date: '2022-08-01'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
library(readr)

```

- In this final project, you will use R in order to evaluate logistic regression models with the objective of building a mortgage application approval/denial classifier. Of interest is modeling the probability that an applicant will be approved or denied as a function observables in order to classify applicants as being ones who will be approved and who will not be approved. The dataset and first questions are the same as Stage 1, but now you will need to use R.

From the GitHub repository, download the .csv file. The dataset contains records on 2,380 applicants for mortgages in Boston. Also at our repo is a description of the variables and a paper published in the American Economic Review that first evaluated the data in order to test for the presence of racial discrimination in the mortgage approval process. You should first read the paper as it provides a detailed discussion of the data and insight on the determinants of the probability of being approved. After reading the paper and importing the dataset into R, do the following:


________________________________________________________________________________________________________
A. The variables in the dataset do not have intuitive names (e.g., the meaning of S3 is unclear). Referencing the data description and the AER paper, identify the qualitative dependent that you will be modeling and the set of covariates that you intend to include in your various models, and rename the variables so that they have (somewhat) intuitive names. Be certain that the debt-to-income ratio and the race, self-employed, marital status, and education indicator variables are included, among other variables.


```{r}
Mortgagestats <- read_csv("Data/hmda_sw.csv",show_col_types = FALSE)

Mortgagestats <- Mortgagestats[c(5,6,9,11,13,20,24,30,34,36,39,40,59)]

# s6, s7, s13, s15, s17, s23a, s27a, s33, s40, s42, s45, S46, school

Coln = c("Loan_Amount", "Action_Taken", "Race","Sex", "Income_Thousands", "Marital_Status", "Self_Employed", "Purchase_Price", "Credit_Approved", "Mortgage_Credit_History", "DTI_Housing", "DTI_Total", "School")

colnames(Mortgagestats) <- Coln

Mortgagestats[Mortgagestats == 999999.4] <- NA

Mortgagestats$Race <- factor(Mortgagestats$Race, levels = c(3,5),labels = c("Black","White"))
Mortgagestats$Action_Taken <- factor(Mortgagestats$Action_Taken, levels = c(1,2,3), labels = c("Approved", "Approved", "Denied"))
Mortgagestats$Sex <- factor(Mortgagestats$Sex, levels = c(1,2,3), labels = c("Male", "Female", "NA"))
Mortgagestats$Marital_Status <- factor(Mortgagestats$Marital_Status)

```
- Above we pull in the data and then begin to clean and prep it for usage
- First we reduce the number of columns to the variables we deemed important, also we rename the columns to more intuitive names that represent what the variable is.
- From there we remove any missing data points which were previously coded as 999,999.4 and end by 


B. Generate summary statistics on the set of variables selected in A, and explain the composition of the sample and of the characteristics of an average (representative) applicant. In the process, you should also generate and histograms and frequency counts on particular variables of interest, which can be referenced in your explanation of the composition of the sample and of a representative applicant.

```{r}

summary(Mortgagestats)


```


C. With the full sample, estimate the logistic regression model, where the deny/approve dummy variable is the response variable and the debt-to-income ratio and the race, self-employed, marital status, and education indicator variables are the co-variates. Graph the ROC curve and calculate the AUC. Also, compute the confusion matrix at alternative cut-off levels, and calculate the classifier sensitivity, specificity, the false-positive rate, the false-negative rate, the model accuracy and error rate to confirm they are the same as those produced by R. Provide a written explanation summarizing the findings.

```{r}

```


D. Next, using 10-fold cross validation, estimate a variety of logistic regression models and evaluate their predictive performance across a range of threshold values in each case. The models can (should) include interaction variables and polynomial terms (e.g., quadratic and cubic variables). Of interest is identifying the model and threshold value that yield the smallest average test misclassification rate; however, you can also calculate model accuracy and the AUC. Document in a table the performance of the various models using the chosen performance measures.

```{r}

```


E. Of the competing models that you estimated and thresholds that you evaluated, identify the superior model for classification purposes. Re-estimate the model with the full sample of data. Then, graph the ROC, calculate the AUC, and compute the confusion matrix at the threshold level associated with the minimum average test mis-classification rate . Calculate the classifier sensitivity and specificity, the false-positive rate, the false negative rate, the accuracy, and overall mis-classification rate. How well does your superior model perform relative to the model estimated in C? Explain. Note that to do so you will need to calculate the confusion matrix from the estimated model in C at the threshold level.


```{r}

```

F. Upload an error-free and well-organized copy of your program and a report that summarizes your modeling efforts and the discussion/explanation of your findings from B, C, D, and E. Be certain to include a table describing the results from the various models you evaluated, and be certain to include the estimation results from your superior model estimated with the full dataset.


```{r}

```


