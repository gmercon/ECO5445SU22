---
title: "Regularization"
author: "Joshua Eubanks"
date: '2022-07-25'
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(gamlr)

sessionInfo()

```

Regularization is essentially another way to say desensitization. What we will do is trade off bias (deviations from minimizing SSR) and variance (variation in predicted values). 

# Examples

We are going to go through multiple examples. 

## NHL 

The data comprise of information about play configuration and the players on ice (including goalies) for every goal from 2002-03 to 2012-14 NHL seasons. Collected using A. C. Thomas’s `nlhscrapr` package. See the Chicago hockey analytics project at `github.com/mataddy/hockey`

- goal -> Info about each goal scored, including homegoal – an indicator for the home team scoring.
- player -> Sparse Matrix with entries for who was on the ice for each goal: +1 for a home team player, -1 for an away team player, zero otherwise.
- team -> Sparse Matrix with indicators for each team*season interaction: +1 for home team, -1 for away team.
- config -> Special teams info. For example, S5v4 is a 5 on 4 powerplay, +1 if it is for the home-team and -1 for the away team

### Data Cleaning

Bringing in data

```{r}
data(hockey) 
```

#### Generate Independent Variables


```{r}
x <- cbind(config,team,player) # cbind binds together two sparse matrices
```

#### Generating dependent variable, Binary response

```{r}
y <- goal$homegoal
```

### Generate Model

```{r}
nhlreg <- gamlr(x, y, verb=TRUE,
	free=1:(ncol(config)+ncol(team)), ## free denotes unpenalized columns
	family="binomial", standardize=FALSE)
```

#### Extracting Coefficents

Let's grab the coefficients of each player

```{r}
# AICc selection 
Baicc <- coef(nhlreg)[colnames(player),]
```

First, a simple gut-check point: the intercept. This is the effect on odds that a goal is home rather than away, regardless of any info about what teams are playing or who is on ice. It's the home ice advantage!  

We find that home-ice increases odds you've scored by 8%

```{r}
exp(coef(nhlreg)[1])
```
Now, lets look at the player effects. The regression finds 646 significant player effects

```{r}
sum(Baicc!=0)
```
Here are the top 10 players

```{r}
Baicc[order(Baicc, decreasing=TRUE)[1:10]]
```

Here are the bottom 10 

```{r}
Baicc[order(Baicc)[1:10]]
```


Specifically, the model says, e.g., that whenever a goal is scored, Pittsburgh's odds of having scored (rather than scored on) increase by a 51% if Sidney Crosby is on the ice.  

```{r}
exp(Baicc["SIDNEY_CROSBY"])
```


And the Blue Jackets (or Kings, pre 2011-12) odds of having scored drop by around 22% if Jack Johnson is on the ice.

```{r}
exp(Baicc["JACK_JOHNSON"])
```

hockey fans among you may feel free to comment in much more detail.

### Standardizing vs Not Standardizing Data

Without `standardize=FALSE`, you'd be multiplying the penalty for each coefficient (player effect) by that player's standard deviation in onice. The players with big SD in onice are guys who play a lot. Players with small SD are those who play little (almost all zeros). So weighting penalty by SD in this case is exactly what you don't want: a bigger penalty for people with many minutes on ice, a smaller penalty for those who seldom play. Indeed, running the regression without `standardize=FALSE` leads to a bunch of farm teamers coming up tops.  

```{r}
nhlreg.std <-  gamlr(x, y, 
	free=1:(ncol(config)+ncol(team)), family="binomial")
Bstd <- coef(nhlreg.std)[colnames(player),]
Bstd[order(Bstd, decreasing=TRUE)[1:10]]
```

NOTE: this is an exceptional case! You almost always want standardize=TRUE.



### Cross-Validation

```{r}
cv.nhlreg <- cv.gamlr(x, y, 
	free=1:(ncol(config)+ncol(team)),
	family="binomial", verb=TRUE, standardize=FALSE)

```


#### Plotting Results

```{r}
par(mfrow=c(1,2))
plot(cv.nhlreg)
plot(cv.nhlreg$gamlr) ## cv.gamlr has included a gamlr object into cv.nhlreg
```


### Lambda Selection

```{r}
log(nhlreg$lambda[which.min(AICc(nhlreg))])
log(nhlreg$lambda[which.min(AIC(nhlreg))])
log(nhlreg$lambda[which.min(BIC(nhlreg))])
log(cv.nhlreg$lambda.min)
log(cv.nhlreg$lambda.1se)
```

AIC and AICc give exactly the same answer here (n>>df) and both are close to the `cv.min` answer.

```{r}
Bcvmin <- coef(cv.nhlreg, select="min")[colnames(player),]
sum(Bcvmin!=0) # around 600
sort(Bcvmin,decreasing=TRUE)[1:10] # similar top 10
```


Both AIC and AICc are trying to approximate the OOS deviance (MSE here). Thus the lambdas at minimum AIC and AICc values are estimates of the lambda which minimizes OOS error -- the same thing targeted with the cv.min rule. Also, in this case, the degrees of freedom are low enough relative to 'n' that AIC works fine, and gives an answer close to AICc. 

The 1se rule accounts for uncertainty about OOS error, and thus chooses a simpler model.

```{r}
Bcv1se <- coef(cv.nhlreg)[colnames(player),]
```

Even though log lambdas are close, df drops by 1/2

```{r}
sum(Bcv1se!=0) # only around 300

```

Top 10 changes a bit as well

```{r}

sort(Bcv1se,decreasing=TRUE)[1:10] # top 10 changes a bit
```

BIC is way more (overly I think) conservative than all these options.

```{r}
Bbic <- coef(nhlreg,select=which.min(BIC(nhlreg)))[colnames(player),]
sum(Bbic!=0) # zero!  Nobody is different from average according to BIC
```


The BIC is trying to find lambda with highest probability of having the minimum OOS error, which is subtly different than finding the lambda corresponding to lowest expected OOS error. For example, if there is more uncertainty about OOS error at the lambda with min expectation, then it could be that another value with higher expected error but lower uncertainty around this value will have a higher probability of being best. In this case, the BIC says there is much uncertainty at everything other than the null model, so that the null model ends up highest probability of being best.

As an aside: note that the null model here is not just an intercept, but rather includes onice configuration info along with information about the team and season. So the BIC is not saying that no players matter, but rather that it cannot confidently tell them apart from their team's average level of play in a given season.

### Comparing Model Selections

Finally, some plots to compare model selections

```{r}
ll <- log(nhlreg$lambda) ## the sequence of lambdas
n <- nrow(goal)
par(mfrow=c(1,2))
plot(cv.nhlreg)
plot(ll, AIC(nhlreg)/n, 
	xlab="log lambda", ylab="IC/n", pch=21, bg="orange")
abline(v=ll[which.min(AIC(nhlreg))], col="orange", lty=3)
abline(v=ll[which.min(BIC(nhlreg))], col="green", lty=3)
abline(v=ll[which.min(AICc(nhlreg))], col="black", lty=3)
points(ll, BIC(nhlreg)/n, pch=21, bg="green")
points(ll, AICc(nhlreg)/n, pch=21, bg="black")
legend("topleft", bty="n",
	fill=c("black","orange","green"),legend=c("AICc","AIC","BIC"))
```

Plot all the answers along the path

```{r}
par(mfrow=c(1,1))
plot(nhlreg, col="grey")
abline(v=ll[which.min(AICc(nhlreg))], col="black", lty=2, lwd=2)
abline(v=ll[which.min(AIC(nhlreg))], col="orange", lty=2, lwd=2)
abline(v=ll[which.min(BIC(nhlreg))], col="green", lty=2, lwd=2)
abline(v=log(cv.nhlreg$lambda.min), col="blue", lty=2, lwd=2)
abline(v=log(cv.nhlreg$lambda.1se), col="purple", lty=2, lwd=2)
legend("topright", bty="n", lwd=2, 
	col=c("black","orange","green","blue","purple"),
	legend=c("AICc","AIC","BIC","CV.min","CV.1se"))
```


## Browsing History

The table has three colums: [machine] id, site [id], [# of] visits

### Data Mangement

```{r}
web <- read.csv("browser-domains.csv")
```

Read in the actual website names and relabel site factor

```{r}
sitenames <- scan("browser-sites.txt", what="character")
web$site <- factor(web$site, levels=1:length(sitenames), labels=sitenames)
```

also factor machine id

```{r}
web$id <- factor(web$id, levels=1:length(unique(web$id)))
```

Let's get total visits per-machine and % of time on each site
`tapply(a,b,c)` does `c(a)` for every level of factor `b`.

```{r}
machinetotals <- as.vector(tapply(web$visits,web$id,sum)) 
visitpercent <- 100*web$visits/machinetotals[web$id]
```

Since there are many sites that some people do not visit, our dataframe could blow out of proportion. We will first need to generate a sparse matrix.

```{r}
xweb <- sparseMatrix(
	i=as.numeric(web$id), j=as.numeric(web$site), x=visitpercent,
	dims=c(nlevels(web$id),nlevels(web$site)),
	dimnames=list(id=levels(web$id), site=levels(web$site)))
```

We can extract values from the sparse matrix. Ex: What sites did household 1 visit?

```{r}
head(xweb[1, xweb[1,]!=0])
```

Read in the spending data 

```{r}
yspend <- read.csv("browser-totalspend.csv", row.names=1)  # use 1st column as row names
yspend <- as.matrix(yspend) ## good practice to move from dataframe to matrix
```


### LASSO


```{r}
spender <- gamlr(xweb, log(yspend), verb=TRUE)

summary(spender)
plot(spender) ## path plot
```

### Extracting and observing coefficients

Do not go to these links.

```{r}
B <- coef(spender) ## the coefficients selected under AICc

B <- B[-1,] # drop intercept and remove STM formatting
B[which.min(B)] ## low spenders spend a lot of time here
B[which.max(B)] ## big spenders hang out here
```



#### Extracting Coefficients Using Other Rules

```{r}
coef(spender, select=which.min(BIC(spender))) ## and BIC instead
```

### Cross-Validation

```{r}
cv.spender <- cv.gamlr(xweb, log(yspend), verb=TRUE,nfold =10)
beta1se <- coef(cv.spender) ## 1se rule; see ?cv.gamlr
betamin <- coef(cv.spender, select="min") ## min cv selection
cbind(beta1se,betamin)[c("tvguide.com","americanexpress.com"),]
```


#### Ploting CV Results

```{r}
par(mfrow=c(1,2))
plot(cv.spender)
plot(cv.spender$gamlr) ## cv.gamlr includes a gamlr object
?gamlr

```


#### Log lambdas selected under various criteria

```{r}
log(spender$lambda[which.min(AICc(spender))])
log(spender$lambda[which.min(AIC(spender))])
log(spender$lambda[which.min(BIC(spender))])
log(cv.spender$lambda.min)
log(cv.spender$lambda.1se)
```



### All Metrics, together in a path plot.

```{r}
plot(spender, col="grey")
abline(v=ll[which.min(AICc(spender))], col="black", lty=2)
abline(v=ll[which.min(AIC(spender))], col="orange", lty=2)
abline(v=ll[which.min(BIC(spender))], col="green", lty=2)
abline(v=log(cv.spender$lambda.min), col="blue", lty=2)
abline(v=log(cv.spender$lambda.1se), col="purple", lty=2)
legend("topright", bty="n", lwd=1, 
	col=c("black","orange","green","blue","purple"),
	legend=c("AICc","AIC","BIC","CV.min","CV.1se"))

```


